search_google:
  description: >
    Perform Google search queries for {topic} using Serper Dev Tool as of {timestamp}. 
    The tool outputs a JSON string.
    The output format should include all extracted data from the search results.
    - Title: [Title of the article]
    - Link: [Link to the article]
    - Snippet: [Snippet of the article]
    - Date: [Date of the article] 
    This will be helpful to the read_articles task to read the most relevant articles.
  expected_output: >
    A JSON string with all extracted data from the search results.
    This will be used to read the articles in the read_articles task.
  agent: google_agent
  output_file: "output/search_results.txt"

read_articles:
  description: >
    Given the context from the search_google task, use the WebScraper tool to read 1-2 articles and summarize the key points.
    If you encounter any errors (e.g., 403, 404, etc.), skip and read the next article.
    Follow this format:
    [Title of the article]
    [Summary of the article]
    [Source URL of the article]
  expected_output: >
    A text format article with 200-300 word summary for each article you read.
    This will be used to draft the final article.
  agent: article_reader
  context: [search_google]
  output_file: "output/research_summary.txt"

scrape_twitter:
  description: >
    Use the Twitter Scraper tool to navigate Twitter and extract the latest {number} tweets about {topic} as of {timestamp}.
    Focus on tweets that are relevant to the topic and have significant engagement.
    The scraper will return a JSON structure containing:
    - tweets: Array of tweet objects
    - trend: The searched trend
    - count: Number of tweets collected
    Each tweet object contains:
    - id: Unique tweet identifier
    - content: Text content of the tweet
    - user: Twitter handle of the author
    - timestamp: When the tweet was posted
    - likes: Number of likes
    - retweets: Number of retweets
    - has_photos: Boolean indicating if the tweet contains images
    Exclude retweets and spam content.
  expected_output: >
    A JSON object containing:
    - tweets: Array of tweet objects with the specified fields
    - trend: The searched trend
    - count: Number of tweets collected
  agent: twitter_agent
  output_file: "output/tweets.json"
twitter_sentiments:
  description: >
    Analyze the sentiment of tweets collected in the scrape_twitter task.
    Identify key themes, emotional tones (positive, negative, neutral), and notable patterns.
    Exclude irrelevant or off-topic tweets from the analysis.
  expected_output: >
    A structured text report containing:
    1. Overall sentiment analysis (percentage breakdown of positive/negative/neutral)
    2. Key themes identified
    3. Notable patterns or trends
    4. Representative examples of each sentiment category
  agent: twitter_sentiment_agent
  context: [scrape_twitter]
  output_file: "output/twitter_sentiments.txt"
write_article:
  description: >
    Combine Twitter and Google findings to write ~300 word article about {topic} as of {timestamp}.
    Article should be engaging and interesting.
    Backup your story with facts, figures and sources.
  expected_output: >
    Markdown article with title and ~300 word content.
  agent: article_writer
  output_file: "output/article.md"
  context: [twitter_sentiments, read_articles]
